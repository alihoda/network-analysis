{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "mount_file_id": "13A--dSL73-86Zzjp5IS9iG2QwKD0Ob9i",
      "authorship_tag": "ABX9TyPEVsn00X8h3v+vQYCuYYdF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alihoda/network-analysis/blob/main/traffic_nodes.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxVhYQTeN2lN"
      },
      "source": [
        "# Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KY16R2BHFjcK"
      },
      "source": [
        "!pip install --upgrade plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q18Jt48VlB65"
      },
      "source": [
        "from datetime import datetime\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import statsmodels.tsa.stattools as sts\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2d-X02bO4R9"
      },
      "source": [
        "# Load Data and Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EOAABYQllyh"
      },
      "source": [
        "def read_csv(csv_path, cols, datetime_col, datetime_format='%d/%m/%Y%H:%M:%S', pkt_cols=None):\n",
        "  \"\"\"\n",
        "  Read csv file and create a dataframe based on the given params.\n",
        "  ## Parameters\n",
        "  - csv_path: The csv file path\n",
        "  - cols: Name of columns that have datetime, Forward and backward packets, and IP addresses.\n",
        "  - datetime_col: Name of the column which contains datetime.\n",
        "  - datetime_format: The format of the datetime_col\n",
        "  - pkt_cols: If dataset contains columns for forward and backward packets, specify them as a list.\n",
        "  \n",
        "  If the dataset doesn't have pkt_cols, it must has column named as pkCount which contains\n",
        "  total packets.\n",
        "  \"\"\"\n",
        "\n",
        "  df = pd.read_csv(csv_path)\n",
        "  if pkt_cols:\n",
        "    df['pktCount'] = df[pkt_cols[0]] + df[pkt_cols[1]]\n",
        "    \n",
        "  df.loc[:, cols]\n",
        "  df[datetime_col] = pd.to_datetime(df[datetime_col], format=datetime_format)\n",
        "  df.set_index(datetime_col, inplace=True)\n",
        "  return df"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tKGaIHDA1sOR"
      },
      "source": [
        "def to_stationary(win_df, win_mean, win_start, win_end, df):\n",
        "  \"\"\"\n",
        "  Check if the given dataframe is stationary or not\n",
        "  and make it stationary if needed.\n",
        "\n",
        "  ## Prameters\n",
        "  - win_df: The window's dataframe to check its stationarity.\n",
        "  - win_mean: The window's mean value\n",
        "  - win_start: The window's start index in main dataframe\n",
        "  - win_end: The window's end index in main dataframe\n",
        "  - df: The main dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  if sts.adfuller(win_df['pktCount'])[1] > 0.05:\n",
        "    arr = (win_df['pktCount'] - win_mean).values.tolist()\n",
        "    df['pktCount'].iloc[win_start:win_end] = arr"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8uGnDoa2CsQ"
      },
      "source": [
        "def extract_time_nodes(df, win_size=10):\n",
        "  time_nodes = []\n",
        "  test_win_start = 0\n",
        "  test_win_end = win_size\n",
        "\n",
        "  while test_win_end < len(df):\n",
        "\n",
        "    ref_win_start = test_win_start\n",
        "    ref_win_end = test_win_end\n",
        "    test_win_start = ref_win_end\n",
        "    test_win_end = test_win_start + win_size\n",
        "\n",
        "    ref_win = df.iloc[ref_win_start:ref_win_end]\n",
        "    test_win = df.iloc[test_win_start:test_win_end]\n",
        "\n",
        "    if not (ref_win.size < 5 or test_win.size < 5):\n",
        "\n",
        "      to_stationary(ref_win, ref_win['pktCount'].mean(), ref_win_start, ref_win_end, df)\n",
        "      to_stationary(test_win, test_win['pktCount'].mean(), test_win_start, test_win_end, df)\n",
        "      \n",
        "      ref_win_mean = round(ref_win['pktCount'].mean(), 2)\n",
        "      ref_win_std = round(ref_win['pktCount'].std(), 2)\n",
        "      test_win_mean = round(test_win['pktCount'].mean(), 2)\n",
        "      test_win_std = round(test_win['pktCount'].std(), 2)\n",
        "      \n",
        "      test_up_braket = ref_win_mean-ref_win_std < test_win_mean+test_win_std < ref_win_mean+ref_win_std\n",
        "      test_bottom_braket = ref_win_mean-ref_win_std < test_win_mean-test_win_std < ref_win_mean+ref_win_std\n",
        "\n",
        "      ref_up_braket = test_win_mean-test_win_std < ref_win_mean+ref_win_std < test_win_mean+test_win_std\n",
        "      ref_bottom_braket = test_win_mean-test_win_std < ref_win_mean-ref_win_std < test_win_mean+test_win_std\n",
        "\n",
        "      if not (ref_up_braket or ref_bottom_braket or test_up_braket or test_bottom_braket):\n",
        "        time_nodes.append(ref_win.index.values[-1])\n",
        "  \n",
        "  return time_nodes"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dfbihmyR3kw9"
      },
      "source": [
        "def plot(df, nodes, title):\n",
        "  \"\"\"Plot given dataframe with its time's nodes\"\"\"\n",
        "\n",
        "  fig = px.line(x=df.index, y=df['pktCount'])\n",
        "  for node in nodes:\n",
        "    time = pd.to_datetime(node)\n",
        "    fig.add_vline(x=node, line_dash='dash', line_color='green')\n",
        "  fig.update_layout(title=title, xaxis_title='DateTime', yaxis_title='Packets')\n",
        "  fig.show()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "53gYgv415jLG"
      },
      "source": [
        "# Working with Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsy6kwW04Cjy"
      },
      "source": [
        "cols = ['Source.IP', 'Destination.IP', 'Timestamp']\n",
        "pkt_cols = ['Total.Fwd.Packets', 'Total.Backward.Packets']\n",
        "csv_path = 'drive/MyDrive/data/Dataset-Unicauca-Version2-87Atts.csv'\n",
        "\n",
        "df_comp = read_csv(csv_path=csv_path, cols=cols, datetime_col='Timestamp', pkt_cols=pkt_cols)\n",
        "df = df_comp.loc['2017-04-26']\n",
        "time_nodes = extract_time_nodes(df)\n",
        "plot(df, time_nodes, '2017-04-26')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}